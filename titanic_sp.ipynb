{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_data= pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>\n",
    "Sibsp is number of sibling in the ship\n",
    "Parch is parents / children aboard the Titanic\n",
    "</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "# Drop non-numeric columns\n",
    "numeric_titanic_data = titanic_data.select_dtypes(include=[np.number])\n",
    "\n",
    "# Now, compute the correlation matrix and plot the heatmap\n",
    "sns.heatmap(numeric_titanic_data.corr(), cmap=\"YlGnBu\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"StratifiedShuffleSplit is a cross-validtor that provides train/test indices to split data into train/test sets while\n",
    "ensuring that the class distribution is preserved\"\"\"\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "\"\"\"this line initializes a stratifiedShuffleSplit object named split. it specifies that we want to perform one split (n_splits=1)\n",
    "and the test set should contain 20% of the data. this mean 80% of data will be used for training\"\"\"\n",
    "split = StratifiedShuffleSplit (n_splits=1,test_size=0.2)\n",
    "\n",
    "\"\"\"in each iteration of the loop, it will generate train/test indices using the split object\n",
    "split() method\n",
    "it iterates over each split and assigns the training indices to train_indices and the testing indices to \n",
    "test_indices\"\"\"\n",
    "\"\"\"\n",
    "titanic_data[[\"Survived\",\"Pclass\",\"Sex\"]]: these columns are used for stratifaction , which means that the spilit is done in such a way that the class \n",
    "distribution of the target vatiable is preserved across the retaining and testing case\n",
    "\"\"\"\n",
    "for train_indices, test_indices  in split.split(titanic_data, titanic_data[[\"Survived\",\"Pclass\",\"Sex\"]]):\n",
    "    \n",
    "    \"\"\"this line selects the rows from the titanic_data DataFrame corresponding to the indices in train_indices and assigns them to a new DataFrame Strat_train_set\"\"\"\n",
    "    Strat_train_set=titanic_data.loc[train_indices]\n",
    "    Strat_test_set= titanic_data.loc[test_indices]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#this line reates the first subplot in a  1x2 grid of subplot. it specifies that the current plot will be the first one\n",
    "plt.subplot(1, 2, 1)\n",
    "#this line plots a histrogram of the \"Survived variable from the training set\"\n",
    "Strat_train_set['Survived'].hist()\n",
    "\n",
    "#this line plots a histrogram of the \"Pclass\" variable from training set\n",
    "Strat_train_set['Pclass'].hist()\n",
    "plt.xlabel('Categories')  # Add x-axis label\n",
    "plt.ylabel('Frequency')  # Add y-axis label\n",
    "plt.title('Training Set')  # Add title for the subplot\n",
    "\n",
    "# This line creates the second subplot in the 1x2 grid of subplots. It specifies that the current plot will be the second one.\n",
    "plt.subplot(1, 2, 2)\n",
    "Strat_test_set['Survived'].hist()\n",
    "Strat_test_set['Pclass'].hist()\n",
    "plt.xlabel('Categories')  # Add x-axis label\n",
    "plt.ylabel('Frequency')  # Add y-axis label\n",
    "plt.title('Testing Set')  # Add title for the subplot\n",
    "\n",
    "plt.tight_layout()  # Adjust subplot layout to prevent overlap\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 712 entries, 165 to 641\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  712 non-null    int64  \n",
      " 1   Survived     712 non-null    int64  \n",
      " 2   Pclass       712 non-null    int64  \n",
      " 3   Name         712 non-null    object \n",
      " 4   Sex          712 non-null    object \n",
      " 5   Age          572 non-null    float64\n",
      " 6   SibSp        712 non-null    int64  \n",
      " 7   Parch        712 non-null    int64  \n",
      " 8   Ticket       712 non-null    object \n",
      " 9   Fare         712 non-null    float64\n",
      " 10  Cabin        160 non-null    object \n",
      " 11  Embarked     711 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 72.3+ KB\n"
     ]
    }
   ],
   "source": [
    "Strat_train_set.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Creating a pipeline </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#these classes are used for creating custom transg=fermors in scikit-learn\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "#This line defines a new class named AgeImputer that inherits from both BaseEstimator and TransformerMixin. This inheritance provides useful methods such as fit() and transform()\n",
    "class AgeImputer(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    # this method is used to fit the transformer to the data. .in this case, the fit() method does nothing because the transformer doesn't learn anything from the data\n",
    "    def fit(self,X,y=None):\n",
    "        return self\n",
    "\n",
    "    #this method is used to transform the data\n",
    "    def transform(self,X):\n",
    "        #creates SimpleImputer object imputer with the strategy set to \"mean\". This imputer will fill missing values in the \"Age\" column with the non-missing values\n",
    "        imputer= SimpleImputer(strategy=\"mean\")\n",
    "        \n",
    "        #applies the filt_transform() method of the SimpleImputer object to the Age column of the input DataFrame X\n",
    "        X['Age'] = imputer.fit_transform(X[['Age']])\n",
    "        \n",
    "        #retyurns the modified DataFrame 'X' with the missing values in the 'Age' column imputed with the mean\n",
    "        return X\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#used to encode categorical integer features as a one-hot numeric array\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "class FeatureEncoder(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self \n",
    "    \n",
    "    def transform(self,X):\n",
    "        encoder=OneHotEncoder()\n",
    "        \n",
    "        #encodes Embarked column using one-hot encoding\n",
    "        \"\"\"encoding using one-hot means representing categorrical data as binary vector\n",
    "        \n",
    "        For example, let's consider the \"Embarked\" column which contains categorical values like \"C\", \"S\", and \"Q\" representing the ports of embarkation.\n",
    "\n",
    "        *With one-hot encoding, each unique category in the \"Embarked\" column will be transformed into a new binary column.\n",
    "         For each row, the binary column corresponding to the category that the row belongs to will have a value of 1, and all other binary columns will have a value of 0.\n",
    "        \n",
    "        *For instance, if a passenger embarked from \"C\", the one-hot encoding would represent this as [1, 0, 0]. If a passenger embarked from \"S\",\n",
    "         it would be represented as [0, 1, 0], and so on.\n",
    "        \"\"\"\n",
    "        matrix = encoder.fit_transform(X[['Embarked']]).toarray()\n",
    "\n",
    "        column_names= [\"C\",\"S\",\"Q\",\"N\"]\n",
    "\n",
    "        #creates column C,S,Q,N and \n",
    "        for i in range(len(matrix.T)): #len(matrix.T) is four. Transformation is done because we want only get one binary digit. with transformation in the first 1d array we have true value of C and so one with the loop\n",
    "            X[column_names[i]]=matrix.T[i]\n",
    "\n",
    "\n",
    "        \n",
    "    \n",
    "        matrix= encoder.fit_transform(X[['Sex']]).toarray()\n",
    "\n",
    "       \n",
    "\n",
    "        column_names=[\"Female\",\"Male\"]\n",
    "\n",
    "        #creates column female and male\n",
    "        for i in range (len(matrix.T)): # len(matrix.T) is two\n",
    "            X[column_names[i]]=matrix.T[i]\n",
    "\n",
    "        return X\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>just for understanding only.\n",
    "->REMOVE LATER\n",
    "</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 179 entries, 679 to 605\n",
      "Data columns (total 18 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  179 non-null    int64  \n",
      " 1   Survived     179 non-null    int64  \n",
      " 2   Pclass       179 non-null    int64  \n",
      " 3   Name         179 non-null    object \n",
      " 4   Sex          179 non-null    object \n",
      " 5   Age          142 non-null    float64\n",
      " 6   SibSp        179 non-null    int64  \n",
      " 7   Parch        179 non-null    int64  \n",
      " 8   Ticket       179 non-null    object \n",
      " 9   Fare         179 non-null    float64\n",
      " 10  Cabin        44 non-null     object \n",
      " 11  Embarked     178 non-null    object \n",
      " 12  C            179 non-null    float64\n",
      " 13  S            179 non-null    float64\n",
      " 14  Q            179 non-null    float64\n",
      " 15  N            179 non-null    float64\n",
      " 16  Female       179 non-null    float64\n",
      " 17  Male         179 non-null    float64\n",
      "dtypes: float64(8), int64(5), object(5)\n",
      "memory usage: 26.6+ KB\n"
     ]
    }
   ],
   "source": [
    "encoder = FeatureEncoder()\n",
    "\n",
    "# Apply transformation\n",
    "transformed_data = encoder.transform(Strat_test_set.copy())  # Passing a copy to keep the original data intact\n",
    "transformed_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=Strat_test_set.copy()\n",
    "\n",
    "X[\"X\"]=transformed_data.T[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>679</th>\n",
       "      <th>186</th>\n",
       "      <th>626</th>\n",
       "      <th>857</th>\n",
       "      <th>596</th>\n",
       "      <th>445</th>\n",
       "      <th>422</th>\n",
       "      <th>516</th>\n",
       "      <th>396</th>\n",
       "      <th>328</th>\n",
       "      <th>...</th>\n",
       "      <th>885</th>\n",
       "      <th>374</th>\n",
       "      <th>424</th>\n",
       "      <th>671</th>\n",
       "      <th>435</th>\n",
       "      <th>56</th>\n",
       "      <th>615</th>\n",
       "      <th>43</th>\n",
       "      <th>0</th>\n",
       "      <th>605</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <td>680</td>\n",
       "      <td>187</td>\n",
       "      <td>627</td>\n",
       "      <td>858</td>\n",
       "      <td>597</td>\n",
       "      <td>446</td>\n",
       "      <td>423</td>\n",
       "      <td>517</td>\n",
       "      <td>397</td>\n",
       "      <td>329</td>\n",
       "      <td>...</td>\n",
       "      <td>886</td>\n",
       "      <td>375</td>\n",
       "      <td>425</td>\n",
       "      <td>672</td>\n",
       "      <td>436</td>\n",
       "      <td>57</td>\n",
       "      <td>616</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Survived</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pclass</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Name</th>\n",
       "      <td>Cardeza, Mr. Thomas Drake Martinez</td>\n",
       "      <td>O'Brien, Mrs. Thomas (Johanna \"Hannah\" Godfrey)</td>\n",
       "      <td>Kirkland, Rev. Charles Leonard</td>\n",
       "      <td>Daly, Mr. Peter Denis</td>\n",
       "      <td>Leitch, Miss. Jessie Wills</td>\n",
       "      <td>Dodge, Master. Washington</td>\n",
       "      <td>Zimmerman, Mr. Leo</td>\n",
       "      <td>Lemore, Mrs. (Amelia Milley)</td>\n",
       "      <td>Olsson, Miss. Elina</td>\n",
       "      <td>Goldsmith, Mrs. Frank John (Emily Alice Brown)</td>\n",
       "      <td>...</td>\n",
       "      <td>Rice, Mrs. William (Margaret Norton)</td>\n",
       "      <td>Palsson, Miss. Stina Viola</td>\n",
       "      <td>Rosblom, Mr. Viktor Richard</td>\n",
       "      <td>Davidson, Mr. Thornton</td>\n",
       "      <td>Carter, Miss. Lucile Polk</td>\n",
       "      <td>Rugg, Miss. Emily</td>\n",
       "      <td>Herman, Miss. Alice</td>\n",
       "      <td>Laroche, Miss. Simonne Marie Anne Andree</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>Lindell, Mr. Edvard Bengtsson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex</th>\n",
       "      <td>male</td>\n",
       "      <td>female</td>\n",
       "      <td>male</td>\n",
       "      <td>male</td>\n",
       "      <td>female</td>\n",
       "      <td>male</td>\n",
       "      <td>male</td>\n",
       "      <td>female</td>\n",
       "      <td>female</td>\n",
       "      <td>female</td>\n",
       "      <td>...</td>\n",
       "      <td>female</td>\n",
       "      <td>female</td>\n",
       "      <td>male</td>\n",
       "      <td>male</td>\n",
       "      <td>female</td>\n",
       "      <td>female</td>\n",
       "      <td>female</td>\n",
       "      <td>female</td>\n",
       "      <td>male</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>36.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>57.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>...</td>\n",
       "      <td>39.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>36.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SibSp</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parch</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ticket</th>\n",
       "      <td>PC 17755</td>\n",
       "      <td>370365</td>\n",
       "      <td>219533</td>\n",
       "      <td>113055</td>\n",
       "      <td>248727</td>\n",
       "      <td>33638</td>\n",
       "      <td>315082</td>\n",
       "      <td>C.A. 34260</td>\n",
       "      <td>350407</td>\n",
       "      <td>363291</td>\n",
       "      <td>...</td>\n",
       "      <td>382652</td>\n",
       "      <td>349909</td>\n",
       "      <td>370129</td>\n",
       "      <td>F.C. 12750</td>\n",
       "      <td>113760</td>\n",
       "      <td>C.A. 31026</td>\n",
       "      <td>220845</td>\n",
       "      <td>SC/Paris 2123</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>349910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fare</th>\n",
       "      <td>512.3292</td>\n",
       "      <td>15.5</td>\n",
       "      <td>12.35</td>\n",
       "      <td>26.55</td>\n",
       "      <td>33.0</td>\n",
       "      <td>81.8583</td>\n",
       "      <td>7.875</td>\n",
       "      <td>10.5</td>\n",
       "      <td>7.8542</td>\n",
       "      <td>20.525</td>\n",
       "      <td>...</td>\n",
       "      <td>29.125</td>\n",
       "      <td>21.075</td>\n",
       "      <td>20.2125</td>\n",
       "      <td>52.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>10.5</td>\n",
       "      <td>65.0</td>\n",
       "      <td>41.5792</td>\n",
       "      <td>7.25</td>\n",
       "      <td>15.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cabin</th>\n",
       "      <td>B51 B53 B55</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>E17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A34</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F33</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B71</td>\n",
       "      <td>B96 B98</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Embarked</th>\n",
       "      <td>C</td>\n",
       "      <td>Q</td>\n",
       "      <td>Q</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>...</td>\n",
       "      <td>Q</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>C</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Female</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Male</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18 rows × 179 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            679  \\\n",
       "PassengerId                                 680   \n",
       "Survived                                      1   \n",
       "Pclass                                        1   \n",
       "Name         Cardeza, Mr. Thomas Drake Martinez   \n",
       "Sex                                        male   \n",
       "Age                                        36.0   \n",
       "SibSp                                         0   \n",
       "Parch                                         1   \n",
       "Ticket                                 PC 17755   \n",
       "Fare                                   512.3292   \n",
       "Cabin                               B51 B53 B55   \n",
       "Embarked                                      C   \n",
       "C                                           1.0   \n",
       "S                                           0.0   \n",
       "Q                                           0.0   \n",
       "N                                           0.0   \n",
       "Female                                      0.0   \n",
       "Male                                        1.0   \n",
       "\n",
       "                                                         186  \\\n",
       "PassengerId                                              187   \n",
       "Survived                                                   1   \n",
       "Pclass                                                     3   \n",
       "Name         O'Brien, Mrs. Thomas (Johanna \"Hannah\" Godfrey)   \n",
       "Sex                                                   female   \n",
       "Age                                                      NaN   \n",
       "SibSp                                                      1   \n",
       "Parch                                                      0   \n",
       "Ticket                                                370365   \n",
       "Fare                                                    15.5   \n",
       "Cabin                                                    NaN   \n",
       "Embarked                                                   Q   \n",
       "C                                                        0.0   \n",
       "S                                                        1.0   \n",
       "Q                                                        0.0   \n",
       "N                                                        0.0   \n",
       "Female                                                   1.0   \n",
       "Male                                                     0.0   \n",
       "\n",
       "                                        626                     857  \\\n",
       "PassengerId                             627                     858   \n",
       "Survived                                  0                       1   \n",
       "Pclass                                    2                       1   \n",
       "Name         Kirkland, Rev. Charles Leonard  Daly, Mr. Peter Denis    \n",
       "Sex                                    male                    male   \n",
       "Age                                    57.0                    51.0   \n",
       "SibSp                                     0                       0   \n",
       "Parch                                     0                       0   \n",
       "Ticket                               219533                  113055   \n",
       "Fare                                  12.35                   26.55   \n",
       "Cabin                                   NaN                     E17   \n",
       "Embarked                                  Q                       S   \n",
       "C                                       0.0                     0.0   \n",
       "S                                       1.0                     0.0   \n",
       "Q                                       0.0                     1.0   \n",
       "N                                       0.0                     0.0   \n",
       "Female                                  0.0                     0.0   \n",
       "Male                                    1.0                     1.0   \n",
       "\n",
       "                                    596                        445  \\\n",
       "PassengerId                         597                        446   \n",
       "Survived                              1                          1   \n",
       "Pclass                                2                          1   \n",
       "Name         Leitch, Miss. Jessie Wills  Dodge, Master. Washington   \n",
       "Sex                              female                       male   \n",
       "Age                                 NaN                        4.0   \n",
       "SibSp                                 0                          0   \n",
       "Parch                                 0                          2   \n",
       "Ticket                           248727                      33638   \n",
       "Fare                               33.0                    81.8583   \n",
       "Cabin                               NaN                        A34   \n",
       "Embarked                              S                          S   \n",
       "C                                   0.0                        0.0   \n",
       "S                                   0.0                        0.0   \n",
       "Q                                   1.0                        1.0   \n",
       "N                                   0.0                        0.0   \n",
       "Female                              1.0                        0.0   \n",
       "Male                                0.0                        1.0   \n",
       "\n",
       "                            422                           516  \\\n",
       "PassengerId                 423                           517   \n",
       "Survived                      0                             1   \n",
       "Pclass                        3                             2   \n",
       "Name         Zimmerman, Mr. Leo  Lemore, Mrs. (Amelia Milley)   \n",
       "Sex                        male                        female   \n",
       "Age                        29.0                          34.0   \n",
       "SibSp                         0                             0   \n",
       "Parch                         0                             0   \n",
       "Ticket                   315082                    C.A. 34260   \n",
       "Fare                      7.875                          10.5   \n",
       "Cabin                       NaN                           F33   \n",
       "Embarked                      S                             S   \n",
       "C                           0.0                           0.0   \n",
       "S                           0.0                           0.0   \n",
       "Q                           1.0                           1.0   \n",
       "N                           0.0                           0.0   \n",
       "Female                      0.0                           1.0   \n",
       "Male                        1.0                           0.0   \n",
       "\n",
       "                             396  \\\n",
       "PassengerId                  397   \n",
       "Survived                       0   \n",
       "Pclass                         3   \n",
       "Name         Olsson, Miss. Elina   \n",
       "Sex                       female   \n",
       "Age                         31.0   \n",
       "SibSp                          0   \n",
       "Parch                          0   \n",
       "Ticket                    350407   \n",
       "Fare                      7.8542   \n",
       "Cabin                        NaN   \n",
       "Embarked                       S   \n",
       "C                            0.0   \n",
       "S                            0.0   \n",
       "Q                            1.0   \n",
       "N                            0.0   \n",
       "Female                       1.0   \n",
       "Male                         0.0   \n",
       "\n",
       "                                                        328  ...  \\\n",
       "PassengerId                                             329  ...   \n",
       "Survived                                                  1  ...   \n",
       "Pclass                                                    3  ...   \n",
       "Name         Goldsmith, Mrs. Frank John (Emily Alice Brown)  ...   \n",
       "Sex                                                  female  ...   \n",
       "Age                                                    31.0  ...   \n",
       "SibSp                                                     1  ...   \n",
       "Parch                                                     1  ...   \n",
       "Ticket                                               363291  ...   \n",
       "Fare                                                 20.525  ...   \n",
       "Cabin                                                   NaN  ...   \n",
       "Embarked                                                  S  ...   \n",
       "C                                                       0.0  ...   \n",
       "S                                                       0.0  ...   \n",
       "Q                                                       1.0  ...   \n",
       "N                                                       0.0  ...   \n",
       "Female                                                  1.0  ...   \n",
       "Male                                                    0.0  ...   \n",
       "\n",
       "                                              885                         374  \\\n",
       "PassengerId                                   886                         375   \n",
       "Survived                                        0                           0   \n",
       "Pclass                                          3                           3   \n",
       "Name         Rice, Mrs. William (Margaret Norton)  Palsson, Miss. Stina Viola   \n",
       "Sex                                        female                      female   \n",
       "Age                                          39.0                         3.0   \n",
       "SibSp                                           0                           3   \n",
       "Parch                                           5                           1   \n",
       "Ticket                                     382652                      349909   \n",
       "Fare                                       29.125                      21.075   \n",
       "Cabin                                         NaN                         NaN   \n",
       "Embarked                                        Q                           S   \n",
       "C                                             0.0                         0.0   \n",
       "S                                             1.0                         0.0   \n",
       "Q                                             0.0                         1.0   \n",
       "N                                             0.0                         0.0   \n",
       "Female                                        1.0                         1.0   \n",
       "Male                                          0.0                         0.0   \n",
       "\n",
       "                                     424                     671  \\\n",
       "PassengerId                          425                     672   \n",
       "Survived                               0                       0   \n",
       "Pclass                                 3                       1   \n",
       "Name         Rosblom, Mr. Viktor Richard  Davidson, Mr. Thornton   \n",
       "Sex                                 male                    male   \n",
       "Age                                 18.0                    31.0   \n",
       "SibSp                                  1                       1   \n",
       "Parch                                  1                       0   \n",
       "Ticket                            370129              F.C. 12750   \n",
       "Fare                             20.2125                    52.0   \n",
       "Cabin                                NaN                     B71   \n",
       "Embarked                               S                       S   \n",
       "C                                    0.0                     0.0   \n",
       "S                                    0.0                     0.0   \n",
       "Q                                    1.0                     1.0   \n",
       "N                                    0.0                     0.0   \n",
       "Female                               0.0                     0.0   \n",
       "Male                                 1.0                     1.0   \n",
       "\n",
       "                                   435                56   \\\n",
       "PassengerId                        436                 57   \n",
       "Survived                             1                  1   \n",
       "Pclass                               1                  2   \n",
       "Name         Carter, Miss. Lucile Polk  Rugg, Miss. Emily   \n",
       "Sex                             female             female   \n",
       "Age                               14.0               21.0   \n",
       "SibSp                                1                  0   \n",
       "Parch                                2                  0   \n",
       "Ticket                          113760         C.A. 31026   \n",
       "Fare                             120.0               10.5   \n",
       "Cabin                          B96 B98                NaN   \n",
       "Embarked                             S                  S   \n",
       "C                                  0.0                0.0   \n",
       "S                                  0.0                0.0   \n",
       "Q                                  1.0                1.0   \n",
       "N                                  0.0                0.0   \n",
       "Female                             1.0                1.0   \n",
       "Male                               0.0                0.0   \n",
       "\n",
       "                             615                                       43   \\\n",
       "PassengerId                  616                                        44   \n",
       "Survived                       1                                         1   \n",
       "Pclass                         2                                         2   \n",
       "Name         Herman, Miss. Alice  Laroche, Miss. Simonne Marie Anne Andree   \n",
       "Sex                       female                                    female   \n",
       "Age                         24.0                                       3.0   \n",
       "SibSp                          1                                         1   \n",
       "Parch                          2                                         2   \n",
       "Ticket                    220845                             SC/Paris 2123   \n",
       "Fare                        65.0                                   41.5792   \n",
       "Cabin                        NaN                                       NaN   \n",
       "Embarked                       S                                         C   \n",
       "C                            0.0                                       1.0   \n",
       "S                            0.0                                       0.0   \n",
       "Q                            1.0                                       0.0   \n",
       "N                            0.0                                       0.0   \n",
       "Female                       1.0                                       1.0   \n",
       "Male                         0.0                                       0.0   \n",
       "\n",
       "                                 0                              605  \n",
       "PassengerId                        1                            606  \n",
       "Survived                           0                              0  \n",
       "Pclass                             3                              3  \n",
       "Name         Braund, Mr. Owen Harris  Lindell, Mr. Edvard Bengtsson  \n",
       "Sex                             male                           male  \n",
       "Age                             22.0                           36.0  \n",
       "SibSp                              1                              1  \n",
       "Parch                              0                              0  \n",
       "Ticket                     A/5 21171                         349910  \n",
       "Fare                            7.25                          15.55  \n",
       "Cabin                            NaN                            NaN  \n",
       "Embarked                           S                              S  \n",
       "C                                0.0                            0.0  \n",
       "S                                0.0                            0.0  \n",
       "Q                                1.0                            1.0  \n",
       "N                                0.0                            0.0  \n",
       "Female                           0.0                            0.0  \n",
       "Male                             1.0                            1.0  \n",
       "\n",
       "[18 rows x 179 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_data.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "679    1.0\n",
       "186    0.0\n",
       "626    1.0\n",
       "857    1.0\n",
       "596    0.0\n",
       "      ... \n",
       "56     0.0\n",
       "615    0.0\n",
       "43     0.0\n",
       "0      1.0\n",
       "605    1.0\n",
       "Name: Male, Length: 179, dtype: float64"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_data[\"Male\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Keep from here</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureDropper(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self,X):\n",
    "        return X.drop([\"Embarked\",\"Name\",\"Ticket\",\"Cabin\",\"Sex\",\"N\"],axis=1,errors=\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#allows us to chain together multiple steps in a machine learning workflow\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "#Inside the Pipeline constructor, a list of tuples is provided.\n",
    "\"\"\"Each tuple represents a step in the pipeline. The tuples contain two elements: a string representing the name of the step \n",
    "and an instance of a transformer or estimator class. \"\"\"\n",
    "pipeline = Pipeline([(\"ageimputer\",AgeImputer()),\n",
    "                     (\"FeatureEncoder\", FeatureEncoder()),\n",
    "                     (\"FeatureDropper\", FeatureDropper())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 179 entries, 679 to 605\n",
      "Data columns (total 7 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  179 non-null    int64  \n",
      " 1   Survived     179 non-null    int64  \n",
      " 2   Pclass       179 non-null    int64  \n",
      " 3   Age          142 non-null    float64\n",
      " 4   SibSp        179 non-null    int64  \n",
      " 5   Parch        179 non-null    int64  \n",
      " 6   Fare         179 non-null    float64\n",
      "dtypes: float64(2), int64(5)\n",
      "memory usage: 15.3 KB\n"
     ]
    }
   ],
   "source": [
    "encoder = FeatureDropper()\n",
    "\n",
    "# Apply transformation\n",
    "transformed_data = encoder.transform(Strat_test_set.copy())  # Passing a copy to keep the original data intact\n",
    "transformed_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "Strat_train_set= pipeline.fit_transform(Strat_train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>C</th>\n",
       "      <th>S</th>\n",
       "      <th>Q</th>\n",
       "      <th>Female</th>\n",
       "      <th>Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>166</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>20.5250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>601</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>27.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571</th>\n",
       "      <td>572</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>53.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>51.4792</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>762</th>\n",
       "      <td>763</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2292</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>294</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.8500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>525</th>\n",
       "      <td>526</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>40.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>51.8625</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>323</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12.3500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>218</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>42.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>27.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>641</th>\n",
       "      <td>642</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>69.3000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>712 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass   Age  SibSp  Parch     Fare    C    S  \\\n",
       "165          166         1       3   9.0      0      2  20.5250  0.0  0.0   \n",
       "600          601         1       2  24.0      2      1  27.0000  0.0  0.0   \n",
       "571          572         1       1  53.0      2      0  51.4792  0.0  0.0   \n",
       "762          763         1       3  20.0      0      0   7.2292  1.0  0.0   \n",
       "293          294         0       3  24.0      0      0   8.8500  0.0  0.0   \n",
       "..           ...       ...     ...   ...    ...    ...      ...  ...  ...   \n",
       "525          526         0       3  40.5      0      0   7.7500  0.0  1.0   \n",
       "6              7         0       1  54.0      0      0  51.8625  0.0  0.0   \n",
       "322          323         1       2  30.0      0      0  12.3500  0.0  1.0   \n",
       "217          218         0       2  42.0      1      0  27.0000  0.0  0.0   \n",
       "641          642         1       1  24.0      0      0  69.3000  1.0  0.0   \n",
       "\n",
       "       Q  Female  Male  \n",
       "165  1.0     0.0   1.0  \n",
       "600  1.0     1.0   0.0  \n",
       "571  1.0     1.0   0.0  \n",
       "762  0.0     0.0   1.0  \n",
       "293  1.0     1.0   0.0  \n",
       "..   ...     ...   ...  \n",
       "525  0.0     0.0   1.0  \n",
       "6    1.0     0.0   1.0  \n",
       "322  0.0     1.0   0.0  \n",
       "217  1.0     0.0   1.0  \n",
       "641  0.0     1.0   0.0  \n",
       "\n",
       "[712 rows x 12 columns]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Strat_train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 712 entries, 165 to 641\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  712 non-null    int64  \n",
      " 1   Survived     712 non-null    int64  \n",
      " 2   Pclass       712 non-null    int64  \n",
      " 3   Age          712 non-null    float64\n",
      " 4   SibSp        712 non-null    int64  \n",
      " 5   Parch        712 non-null    int64  \n",
      " 6   Fare         712 non-null    float64\n",
      " 7   C            712 non-null    float64\n",
      " 8   S            712 non-null    float64\n",
      " 9   Q            712 non-null    float64\n",
      " 10  Female       712 non-null    float64\n",
      " 11  Male         712 non-null    float64\n",
      "dtypes: float64(7), int64(5)\n",
      "memory usage: 72.3 KB\n"
     ]
    }
   ],
   "source": [
    "Strat_train_set.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preproceesing step commonly used in machine learning pipelines to standardize the features by removing the mean and scaling to unit varience\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#preparing data\n",
    "X=Strat_train_set.drop(['Survived'],axis=1)\n",
    "Y=Strat_train_set['Survived']\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\"\"\"\n",
    "*Fitting: When you call scaler.fit(X), it computes the mean and standard deviation for each feature in your dataset X. \n",
    "This step analyzes the distribution of each feature and calculates the necessary parameters for standardization.\n",
    "\n",
    "*Transforming: After fitting, scaler.transform(X) scales each feature in the dataset according to the mean and standard deviation calculated during the fitting step. \n",
    "This scaling ensures that each feature has a mean of 0 and a standard deviation of 1.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "#how the mean can be effectively zero after standardization?\n",
    "\"\"\"\n",
    "*Subtracting the Mean: In the standardization process, we subtract the mean of each feature from all the values of that feature. \n",
    "This effectively centers the distribution of each feature around zero.\n",
    "\n",
    "*Mean-Centered Distribution: After standardization, the distribution of each feature is centered around zero. \n",
    "This means that the average value of the feature (the mean) across the dataset becomes zero. However, the individual values of the feature can still vary above and below zero.\n",
    "\n",
    "*Mean Value is Relative: When we say the mean of a feature is zero after standardization, it's a relative statement. \n",
    "It means that, on average, the feature values are balanced around zero. The original mean of the feature might not be exactly zero, but after standardization, it's shifted to zero\n",
    "\"\"\"\n",
    "\n",
    "#how is the standard deviation 1?\n",
    "\"\"\"\n",
    "*Scaling: After centering the data by subtracting the mean, the next step in standardization is to scale each feature so that it has a standard deviation of 1. \n",
    "This is achieved by dividing each feature by its standard deviation.\n",
    "\n",
    "*Unit Variance: By dividing each feature by its standard deviation, we ensure that the variance of each feature becomes 1. \n",
    "Since the standard deviation is the square root of the variance, dividing by the standard deviation effectively scales the variance to 1.\n",
    "\n",
    "*Relative Standardization: Similar to the mean becoming zero, the standard deviation becoming 1 is a relative measure. \n",
    "It means that the spread or dispersion of the feature values is consistent across features after standardization.\n",
    "\"\"\"\n",
    "\n",
    "#Why do we do it?:\n",
    "\"\"\"\n",
    "*Feature Scaling: Many machine learning algorithms perform better when the features are on the same scale. Standardizing the features ensures that they have similar ranges of values, \n",
    "preventing features with larger scales from dominating those with smaller scales during model training.\n",
    "\n",
    "*Algorithm Performance: Some algorithms, such as gradient descent-based optimization algorithms, converge faster when features are scaled. \n",
    "Additionally, distance-based algorithms like K-Nearest Neighbors or clustering algorithms like K-Means are heavily influenced by the scale of features. \n",
    "Standardization ensures that these algorithms work effectively.\n",
    "\n",
    "*Assumption Fulfillment: Some machine learning models assume that the features are standardized. By performing feature scaling, you ensure that your data adheres to these assumptions,\n",
    " potentially leading to more accurate and reliable model predictions.\n",
    "\"\"\"\n",
    "X_data= scaler.fit_transform(X)\n",
    "Y_data= Y.to_numpy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> (Model Selection )\n",
    "Model deployment\n",
    "<h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>HyperParameter</h4>\n",
    "<p>\n",
    "Hyperparamter are configuration setting external to the model that cannot be learned from the training data directly but are used to guide the learning process. the y are set prior to training and remain constant during the training process.Here's a breakdown:\n",
    "\n",
    "1.Model Parameters vs. Hyperparameters:\n",
    "\n",
    "*Model Parameters: These are internal to the model and are learned from the training data during the training process. For example, the weights in a neural network or the coefficients in a linear regression model.\n",
    "\n",
    "*Hyperparameters: These are external to the model and are used to control the learning process. They are set before the training process begins and affect how the model learns the optimal parameters from the data.\n",
    "\n",
    "2 Examples of Hyperparameters:\n",
    "\n",
    "*Learning Rate: Used in optimization algorithms (e.g., gradient descent) to control the step size when updating model parameters during training.\n",
    "\n",
    "*Number of Hidden Layers and Units in Neural Networks: These define the architecture of the neural network and influence its capacity to learn complex patterns.\n",
    "\n",
    "*Regularization Parameters: Such as L1 or L2 regularization strength, used to prevent overfitting by penalizing large parameter values.\n",
    "Kernel Parameters in Support Vector Machines (SVMs): For example, the choice of kernel (linear, polynomial, radial basis function) and its associated parameters.\n",
    "\n",
    "*Number of Trees and Depth in Random Forests: These affect the complexity of the ensemble model and its ability to capture relationships in the data.\n",
    "\n",
    "3 Importance of Hyperparameters:\n",
    "\n",
    "*Hyperparameters significantly impact the performance and behavior of the model.\n",
    "*Choosing appropriate hyperparameters is crucial for achieving good model performance and generalization to unseen data.\n",
    "*Hyperparameter tuning involves searching for the optimal combination of hyperparameters that results in the best model performance.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color: red;\">watch the documentation of randomForrest</h2>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'After fitting, you can access various attributes of the grid_search object, such as best_params_, best_score_, cv_results_, etc., \\nto analyze the results and identify the best hyperparameters for your model.'"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#used to create a random forest classifier, ehich is an ensemble learning method based on decision tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "#implements a grid search algorithm to find the best hyperparamter fro a given model\n",
    "# It systematically evaluates the model performance for each combination of hyperparameters specified in a grid.\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#initializes a Random Forest classifier instance with default hyperparameters.\n",
    "clf = RandomForestClassifier()\n",
    "\n",
    "# each hyperparamter defined in the parameter grid\n",
    "\"\"\"\n",
    "*n_estimators:\n",
    "This hyperparameter represents the number of trees in the random forest ensemble.\n",
    "Each tree in the forest is built independently, and the final prediction is made by averaging (for regression) or voting (for classification) over all trees.\n",
    "Increasing the number of trees generally improves the performance of the random forest, but it also increases the computational cost.\n",
    "Having more trees can make the model more robust and less prone to overfitting.\n",
    "\n",
    "*max_depth:\n",
    "This hyperparameter controls the maximum depth of each decision tree in the forest.\n",
    "A decision tree with a larger depth can capture more complex patterns in the data.\n",
    "However, deeper trees are more likely to overfit the training data, capturing noise rather than signal.\n",
    "Setting this parameter to None allows the trees to grow until all leaves are pure or until all leaves contain less than min_samples_split samples.\n",
    "\n",
    "*min_samples_split:\n",
    "This hyperparameter specifies the minimum number of samples required to split an internal node.\n",
    "If a node has fewer samples than min_samples_split, it will not be split further, and it becomes a leaf node.\n",
    "Increasing this parameter can help prevent the model from overfitting by requiring a minimum amount of data in each split.\n",
    "However, setting it too high may cause underfitting, where the model fails to capture the underlying patterns in the data\n",
    "\"\"\"\n",
    "#The parameter \"n_estimators\" in the grid [10, 100, 200, 500] represents the number of trees in the random forest ensemble. Let's discuss why these particular values are chosen and what they signify:\n",
    "\"\"\"\n",
    "1) 10, 100, 200, 500:\n",
    "*These values represent the number of trees to be included in the random forest.\n",
    "\n",
    "*They are chosen based on a combination of practical considerations and empirical observations.\n",
    "\n",
    "*10: A small number of trees can be useful for quick model prototyping and experimentation. \n",
    "It's also less computationally intensive compared to larger ensembles, making it suitable for datasets with fewer features or smaller sample sizes.\n",
    "\n",
    "*100: This is a commonly used value for \"n_estimators\" in random forest implementations. \n",
    "It strikes a balance between computational efficiency and model performance. Empirical studies have shown that increasing the number of trees beyond 100 often leads to diminishing returns in terms of predictive performance improvement.\n",
    "\n",
    "*200, 500: These values represent larger ensembles, which can potentially capture more complex patterns in the data.\n",
    " However, they come at the cost of increased computational resources and longer training times. In practice, \n",
    " such large numbers of trees are typically used when dealing with extremely high-dimensional datasets or when striving for maximum predictive accuracy without concern for computational constraints\n",
    "\n",
    "\n",
    "2) Choosing the Value:\n",
    "\n",
    "*The choice of the specific values for \"n_estimators\" depends on factors such as the size and complexity of the dataset, computational resources available, \n",
    "and the desired trade-off between model performance and training time.\n",
    "\n",
    "*It's common practice to start with a smaller number of trees (e.g., 10 or 100) and gradually increase it while monitoring the model's performance on validation data. \n",
    "This helps identify the point of diminishing returns where adding more trees doesn't significantly improve performance.\n",
    "\"\"\"\n",
    "\n",
    "#hyperparameters \"max_depth\" and \"min_samples_split\" along with the values provided in the grid:\n",
    "\"\"\"\n",
    "1  max_depth:\n",
    "\n",
    "*This hyperparameter controls the maximum depth of each decision tree in the random forest.\n",
    "\n",
    "*The values provided in the grid are [None, 5, 10].\n",
    "\n",
    "*None: When max_depth is set to None, the decision trees are expanded until all leaves are pure or until all leaves contain less than min_samples_split samples. \n",
    "Essentially, it allows the trees to grow until they have captured all the information in the data, potentially leading to very deep trees.\n",
    "\n",
    "*5, 10: These values represent specific depths for the decision trees.\n",
    " Setting a maximum depth for the trees limits their complexity and prevents overfitting to some extent.\n",
    "   A smaller value like 5 constrains the trees to capture simpler patterns, whereas a larger value like 10 allows them to capture more complex relationships in the data.\n",
    "\n",
    "2    min_samples_split:\n",
    "*This hyperparameter specifies the minimum number of samples required to split an internal node.\n",
    "\n",
    "*The values provided in the grid are [2, 3, 4].\n",
    "\n",
    "*2: This indicates that a node will only be split if it contains at least 2 samples. \n",
    "Having a low min_samples_split can result in very detailed trees, potentially capturing noise in the data and leading to overfitting.\n",
    "\n",
    "*3, 4: These values set a higher threshold for node splitting. By increasing min_samples_split, the decision trees become less complex and more generalized, \n",
    "reducing the risk of overfitting. However, setting it too high may lead to underfitting, \n",
    "where the trees fail to capture important patterns in the data due to overly simplistic splits.\n",
    "   \"\"\"\n",
    "\n",
    "param_grid=[{\n",
    "    \"n_estimators\":[10,100,200,500], \"max_depth\":[None,5,10], \"min_samples_split\":[2,3,4]\n",
    "}]\n",
    "\n",
    "#Grid Search Cross-Validation\n",
    "\"\"\"\n",
    "*GridSearchCV: This class performs an exhaustive search over specified parameter values for an estimator.\n",
    " It evaluates the performance of each combination of hyperparameters using cross-validation.\n",
    "*clf: The estimator (Random Forest classifier) to be fitted.\n",
    "*param_grid: The parameter grid to search.\n",
    "*cv=3: Number of folds for cross-validation.\n",
    "*scoring=\"accuracy\": The scoring metric used to evaluate the performance of the model.\n",
    "*return_train_score=True: Indicates whether to include training scores in the results.\n",
    "\"\"\"\n",
    "grid_search = GridSearchCV(clf, param_grid, cv =3, scoring =\"accuracy\", return_train_score=True)\n",
    "\n",
    "#Fitting the Grid Search\n",
    "\"\"\"\n",
    "This line fits the GridSearchCV object to the provided data (X_data, Y_data). \n",
    "It performs the grid search by training the Random Forest classifier with different combinations of hyperparameters and evaluates each model's performance using cross-validation.\n",
    "\"\"\"\n",
    "grid_search.fit(X_data, Y_data)\n",
    "\n",
    "#Accessing Results\n",
    "\"\"\"After fitting, you can access various attributes of the grid_search object, such as best_params_, best_score_, cv_results_, etc., \n",
    "to analyze the results and identify the best hyperparameters for your model.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_clf=grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(max_depth=10)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=10)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(max_depth=10)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "Strat_test_set= pipeline.fit_transform(Strat_test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>C</th>\n",
       "      <th>S</th>\n",
       "      <th>Q</th>\n",
       "      <th>Female</th>\n",
       "      <th>Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>679</th>\n",
       "      <td>680</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>36.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>512.3292</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>187</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>29.52993</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>15.5000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>626</th>\n",
       "      <td>627</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>57.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12.3500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>857</th>\n",
       "      <td>858</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>51.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26.5500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>597</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>29.52993</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>33.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>21.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.5000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>615</th>\n",
       "      <td>616</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>24.00000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>65.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3.00000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>41.5792</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>22.00000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>606</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>36.00000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>15.5500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>179 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass       Age  SibSp  Parch      Fare    C  \\\n",
       "679          680         1       1  36.00000      0      1  512.3292  1.0   \n",
       "186          187         1       3  29.52993      1      0   15.5000  0.0   \n",
       "626          627         0       2  57.00000      0      0   12.3500  0.0   \n",
       "857          858         1       1  51.00000      0      0   26.5500  0.0   \n",
       "596          597         1       2  29.52993      0      0   33.0000  0.0   \n",
       "..           ...       ...     ...       ...    ...    ...       ...  ...   \n",
       "56            57         1       2  21.00000      0      0   10.5000  0.0   \n",
       "615          616         1       2  24.00000      1      2   65.0000  0.0   \n",
       "43            44         1       2   3.00000      1      2   41.5792  1.0   \n",
       "0              1         0       3  22.00000      1      0    7.2500  0.0   \n",
       "605          606         0       3  36.00000      1      0   15.5500  0.0   \n",
       "\n",
       "       S    Q  Female  Male  \n",
       "679  0.0  0.0     0.0   1.0  \n",
       "186  1.0  0.0     1.0   0.0  \n",
       "626  1.0  0.0     0.0   1.0  \n",
       "857  0.0  1.0     0.0   1.0  \n",
       "596  0.0  1.0     1.0   0.0  \n",
       "..   ...  ...     ...   ...  \n",
       "56   0.0  1.0     1.0   0.0  \n",
       "615  0.0  1.0     1.0   0.0  \n",
       "43   0.0  0.0     1.0   0.0  \n",
       "0    0.0  1.0     0.0   1.0  \n",
       "605  0.0  1.0     0.0   1.0  \n",
       "\n",
       "[179 rows x 12 columns]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Strat_test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test= Strat_test_set.drop(['Survived'], axis=1)\n",
    "Y_test = Strat_test_set['Survived']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_data_test=scaler.fit_transform(X_test)\n",
    "Y_data_test =Y_test.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9050279329608939"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_clf.score(X_data_test, Y_data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data=pipeline.fit_transform(titanic_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>C</th>\n",
       "      <th>S</th>\n",
       "      <th>Q</th>\n",
       "      <th>Female</th>\n",
       "      <th>Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>887</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>888</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>889</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>890</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>891</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass        Age  SibSp  Parch     Fare    C  \\\n",
       "0              1         0       3  22.000000      1      0   7.2500  0.0   \n",
       "1              2         1       1  38.000000      1      0  71.2833  1.0   \n",
       "2              3         1       3  26.000000      0      0   7.9250  0.0   \n",
       "3              4         1       1  35.000000      1      0  53.1000  0.0   \n",
       "4              5         0       3  35.000000      0      0   8.0500  0.0   \n",
       "..           ...       ...     ...        ...    ...    ...      ...  ...   \n",
       "886          887         0       2  27.000000      0      0  13.0000  0.0   \n",
       "887          888         1       1  19.000000      0      0  30.0000  0.0   \n",
       "888          889         0       3  29.699118      1      2  23.4500  0.0   \n",
       "889          890         1       1  26.000000      0      0  30.0000  1.0   \n",
       "890          891         0       3  32.000000      0      0   7.7500  0.0   \n",
       "\n",
       "       S    Q  Female  Male  \n",
       "0    0.0  1.0     0.0   1.0  \n",
       "1    0.0  0.0     1.0   0.0  \n",
       "2    0.0  1.0     1.0   0.0  \n",
       "3    0.0  1.0     1.0   0.0  \n",
       "4    0.0  1.0     0.0   1.0  \n",
       "..   ...  ...     ...   ...  \n",
       "886  0.0  1.0     0.0   1.0  \n",
       "887  0.0  1.0     1.0   0.0  \n",
       "888  0.0  1.0     1.0   0.0  \n",
       "889  0.0  0.0     0.0   1.0  \n",
       "890  1.0  0.0     0.0   1.0  \n",
       "\n",
       "[891 rows x 12 columns]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_final=final_data.drop(['Survived'], axis=1)\n",
    "Y_final=final_data['Survived']\n",
    "\n",
    "scaler=StandardScaler()\n",
    "X_data_final= scaler.fit_transform(X_final)\n",
    "Y_data_final= Y_final.to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=3, estimator=RandomForestClassifier(),\n",
       "             param_grid=[{&#x27;max_depth&#x27;: [None, 5, 10],\n",
       "                          &#x27;min_samples_split&#x27;: [2, 3, 4],\n",
       "                          &#x27;n_estimators&#x27;: [10, 100, 200, 500]}],\n",
       "             return_train_score=True, scoring=&#x27;accuracy&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=3, estimator=RandomForestClassifier(),\n",
       "             param_grid=[{&#x27;max_depth&#x27;: [None, 5, 10],\n",
       "                          &#x27;min_samples_split&#x27;: [2, 3, 4],\n",
       "                          &#x27;n_estimators&#x27;: [10, 100, 200, 500]}],\n",
       "             return_train_score=True, scoring=&#x27;accuracy&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=3, estimator=RandomForestClassifier(),\n",
       "             param_grid=[{'max_depth': [None, 5, 10],\n",
       "                          'min_samples_split': [2, 3, 4],\n",
       "                          'n_estimators': [10, 100, 200, 500]}],\n",
       "             return_train_score=True, scoring='accuracy')"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prod_clf = RandomForestClassifier()\n",
    "\n",
    "param_grid=[{\n",
    "    \"n_estimators\":[10,100,200,500], \"max_depth\":[None,5,10], \"min_samples_split\":[2,3,4]\n",
    "}]\n",
    "\n",
    "#Grid Search Cross-Validation\n",
    "grid_search = GridSearchCV(prod_clf, param_grid, cv =3, scoring =\"accuracy\", return_train_score=True)\n",
    "\n",
    "#Fitting the Grid Search\n",
    "grid_search.fit(X_data_final, Y_data_final)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod_final_clf= grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(max_depth=10, min_samples_split=4, n_estimators=200)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=10, min_samples_split=4, n_estimators=200)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(max_depth=10, min_samples_split=4, n_estimators=200)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prod_final_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_test_data= pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_test_data= pipeline.fit_transform(titanic_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>C</th>\n",
       "      <th>S</th>\n",
       "      <th>Q</th>\n",
       "      <th>Female</th>\n",
       "      <th>Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>34.50000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>47.00000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>62.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>27.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>22.00000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>1305</td>\n",
       "      <td>3</td>\n",
       "      <td>30.27259</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>1306</td>\n",
       "      <td>1</td>\n",
       "      <td>39.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>108.9000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>1307</td>\n",
       "      <td>3</td>\n",
       "      <td>38.50000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>1308</td>\n",
       "      <td>3</td>\n",
       "      <td>30.27259</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>1309</td>\n",
       "      <td>3</td>\n",
       "      <td>30.27259</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>22.3583</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Pclass       Age  SibSp  Parch      Fare    C    S    Q  \\\n",
       "0            892       3  34.50000      0      0    7.8292  0.0  1.0  0.0   \n",
       "1            893       3  47.00000      1      0    7.0000  0.0  0.0  1.0   \n",
       "2            894       2  62.00000      0      0    9.6875  0.0  1.0  0.0   \n",
       "3            895       3  27.00000      0      0    8.6625  0.0  0.0  1.0   \n",
       "4            896       3  22.00000      1      1   12.2875  0.0  0.0  1.0   \n",
       "..           ...     ...       ...    ...    ...       ...  ...  ...  ...   \n",
       "413         1305       3  30.27259      0      0    8.0500  0.0  0.0  1.0   \n",
       "414         1306       1  39.00000      0      0  108.9000  1.0  0.0  0.0   \n",
       "415         1307       3  38.50000      0      0    7.2500  0.0  0.0  1.0   \n",
       "416         1308       3  30.27259      0      0    8.0500  0.0  0.0  1.0   \n",
       "417         1309       3  30.27259      1      1   22.3583  1.0  0.0  0.0   \n",
       "\n",
       "     Female  Male  \n",
       "0       0.0   1.0  \n",
       "1       1.0   0.0  \n",
       "2       0.0   1.0  \n",
       "3       0.0   1.0  \n",
       "4       1.0   0.0  \n",
       "..      ...   ...  \n",
       "413     0.0   1.0  \n",
       "414     1.0   0.0  \n",
       "415     0.0   1.0  \n",
       "416     0.0   1.0  \n",
       "417     0.0   1.0  \n",
       "\n",
       "[418 rows x 11 columns]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 11 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  418 non-null    int64  \n",
      " 1   Pclass       418 non-null    int64  \n",
      " 2   Age          418 non-null    float64\n",
      " 3   SibSp        418 non-null    int64  \n",
      " 4   Parch        418 non-null    int64  \n",
      " 5   Fare         417 non-null    float64\n",
      " 6   C            418 non-null    float64\n",
      " 7   S            418 non-null    float64\n",
      " 8   Q            418 non-null    float64\n",
      " 9   Female       418 non-null    float64\n",
      " 10  Male         418 non-null    float64\n",
      "dtypes: float64(7), int64(4)\n",
      "memory usage: 36.1 KB\n"
     ]
    }
   ],
   "source": [
    "final_test_data.info()\n",
    "\"\"\"there is one null value\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_final_test= final_test_data\n",
    "X_final_test= X_final_test.fillna(method=\"ffill\")\n",
    "\n",
    "scaler= StandardScaler()\n",
    "X_data_final_test= scaler.fit_transform(X_final_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions= prod_final_clf.predict(X_data_final_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df= pd.DataFrame(titanic_test_data['PassengerId'])\n",
    "final_df['Survived']= predictions\n",
    "final_df.to_csv(\"predictions.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>1305</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>1306</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>1307</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>1308</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>1309</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived\n",
       "0            892         0\n",
       "1            893         0\n",
       "2            894         0\n",
       "3            895         0\n",
       "4            896         1\n",
       "..           ...       ...\n",
       "413         1305         0\n",
       "414         1306         1\n",
       "415         1307         0\n",
       "416         1308         0\n",
       "417         1309         1\n",
       "\n",
       "[418 rows x 2 columns]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
